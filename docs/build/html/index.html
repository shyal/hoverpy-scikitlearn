<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Speeding up Machine Learning using a high-performance Go proxy. &mdash; social_media 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="social_media 1.0 documentation" href="#" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="speeding-up-machine-learning-using-a-high-performance-go-proxy">
<h1>Speeding up Machine Learning using a high-performance Go proxy.<a class="headerlink" href="#speeding-up-machine-learning-using-a-high-performance-go-proxy" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
<ul class="simple">
</ul>
</div>
<p>At times I want to grab a bunch of data, use it, and spit something out the other end. From time to time I get paid to do this, too. But the world of online dependencies is far less predictable than I&#8217;d like it to be, a quick browse of your own bookmarks should confirm this to you. Anything that can add predictability to my workflow is surely something worth investigating, and incorporating into my toolset.</p>
<p>Well I recently came across an ultra-high-performance proxy, written in Go, called <a class="reference external" href="http://www.hoverfly.io/">HoverFly</a>. So I decided to write a light-weight Python binding to it: <a class="reference external" href="http://www.hoverpy.io/">HoverPy</a>. HoverFly enables me to offline any data I want, while still being able to interact with it as if I were hitting the real endpoint. In this short article, I&#8217;ll take you through using this very thin Python layer to build a classifier using SciKitLearn, with HackerNews and Reddit as its endpoints.</p>
<p>What I really, really like about Hoverfly, is that it loads so fast in the background. Working with it feels completely transparent, and as you&#8217;ll see I can include its data in my repos; pull that data in for my main functionality, and for my unit testing too. This makes my work 100% water-right, blazingly fast, and failure proof.</p>
<div class="section" id="data-mining-hackernews-and-reddit">
<h2>Data mining HackerNews and Reddit<a class="headerlink" href="#data-mining-hackernews-and-reddit" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s get going:</p>
<div class="highlight-bash"><div class="highlight"><pre>pip install hoverpy haxor praw
python
</pre></div>
</div>
<div class="section" id="lib-hnminer-py">
<h3>./lib/hnMiner.py<a class="headerlink" href="#lib-hnminer-py" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s get the top 100 posts on HackerNews</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">hoverpy</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">hackernews</span> <span class="kn">import</span> <span class="n">HackerNews</span>


<span class="k">def</span> <span class="nf">getHNData</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">sub</span><span class="o">=</span><span class="s">&quot;showstories&quot;</span><span class="p">):</span>
    <span class="n">dbpath</span> <span class="o">=</span> <span class="s">&quot;data/hn.</span><span class="si">%s</span><span class="s">.db&quot;</span> <span class="o">%</span> <span class="n">sub</span>
    <span class="n">capture</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">dbpath</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">hoverpy</span><span class="o">.</span><span class="n">HoverPy</span><span class="p">(</span><span class="n">capture</span><span class="o">=</span><span class="n">capture</span><span class="p">,</span> <span class="n">dbpath</span><span class="o">=</span><span class="n">dbpath</span><span class="p">,</span> <span class="n">httpsToHttp</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="n">hn</span> <span class="o">=</span> <span class="n">HackerNews</span><span class="p">()</span>
        <span class="n">titles</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;GETTING HACKERNEWS </span><span class="si">%s</span><span class="s"> DATA&quot;</span> <span class="o">%</span> <span class="n">sub</span><span class="p">)</span>
        <span class="n">subs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&quot;showstories&quot;</span><span class="p">:</span> <span class="n">hn</span><span class="o">.</span><span class="n">show_stories</span><span class="p">,</span>
                <span class="s">&quot;askstories&quot;</span><span class="p">:</span> <span class="n">hn</span><span class="o">.</span><span class="n">ask_stories</span><span class="p">,</span>
                <span class="s">&quot;jobstories&quot;</span><span class="p">:</span> <span class="n">hn</span><span class="o">.</span><span class="n">job_stories</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">story_id</span> <span class="ow">in</span> <span class="n">subs</span><span class="p">[</span><span class="n">sub</span><span class="p">](</span><span class="n">limit</span><span class="o">=</span><span class="n">limit</span><span class="p">):</span>
            <span class="n">story</span> <span class="o">=</span> <span class="n">hn</span><span class="o">.</span><span class="n">get_item</span><span class="p">(</span><span class="n">story_id</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="n">story</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
            <span class="n">titles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">story</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;got </span><span class="si">%i</span><span class="s"> hackernews titles&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">titles</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">titles</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">getHNData</span><span class="p">(</span><span class="s">&quot;topstories&quot;</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>We can do the same with <code class="docutils literal"><span class="pre">lib/redditMiner.py</span></code>.</p>
<p>Let&#8217;s run this, and get the top 100 titles on HN:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>./hn_titles.py --capture

<span class="o">[</span>...<span class="o">]</span>
London house prices are having a relatively bad December
Interview with Max Levchin

<span class="nb">time </span>taken: 15.888608 seconds.
</pre></div>
</div>
<p>Time taken: <strong>15.888608 seconds</strong>. I don&#8217;t know about you, but working with dependencies that take around 15 seconds on each run is simply not workable. So Let&#8217;s now see what happens when we run this code in simulate mode.</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>./hn_titles.py --capture

<span class="o">[</span>...<span class="o">]</span>
London house prices are having a relatively bad December
Interview with Max Levchin

<span class="nb">time </span>taken: 0.196227 seconds.
</pre></div>
</div>
<p>Time taken: <strong>0.196227 seconds</strong>. That&#8217;s an 80x speed-up: fast enough to collect a meaningful chunk of data transparently.</p>
</div>
</div>
<div class="section" id="putting-our-miners-together">
<h2>Putting our miners together<a class="headerlink" href="#putting-our-miners-together" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s go ahead and write a <code class="docutils literal"><span class="pre">doMining</span></code> function that&#8217;ll bring in all the data we need from the HN sections, and Reddit subs.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">subs</span> <span class="o">=</span> <span class="p">[(</span><span class="s">&#39;hn&#39;</span><span class="p">,</span> <span class="s">&#39;showstories&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;hn&#39;</span><span class="p">,</span> <span class="s">&#39;askstories&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;hn&#39;</span><span class="p">,</span> <span class="s">&#39;jobstories&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;republican&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;democrat&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;linux&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;python&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;music&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;movies&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;literature&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;books&#39;</span><span class="p">)]</span>


<span class="k">def</span> <span class="nf">doMining</span><span class="p">():</span>

    <span class="n">titles</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">target</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="kn">from</span> <span class="nn">hnMiner</span> <span class="kn">import</span> <span class="n">getHNData</span>
    <span class="kn">from</span> <span class="nn">redditMiner</span> <span class="kn">import</span> <span class="n">getRedditData</span>

    <span class="n">getter</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;hn&#39;</span><span class="p">:</span> <span class="n">getHNData</span><span class="p">,</span> <span class="s">&#39;reddit&#39;</span><span class="p">:</span> <span class="n">getRedditData</span><span class="p">}</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subs</span><span class="p">)):</span>
        <span class="n">subTitles</span> <span class="o">=</span> <span class="n">getter</span><span class="p">[</span><span class="n">subs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]](</span>
            <span class="n">sub</span><span class="o">=</span><span class="n">subs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">titles</span> <span class="o">+=</span> <span class="n">subTitles</span>
        <span class="n">target</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">subTitles</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">titles</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">doMining</span><span class="p">()</span>
</pre></div>
</div>
<p>That&#8217;s really all we need, and thanks to HoverFly the entire process, once cached, is blazingly fast. Let&#8217;s move on to our next step.</p>
</div>
<div class="section" id="building-an-hn-or-reddit-classifier">
<h2>Building an HN or Reddit classifier<a class="headerlink" href="#building-an-hn-or-reddit-classifier" title="Permalink to this headline">¶</a></h2>
<div class="figure">
<img alt="hat" src="_images/hat.jpg" />
</div>
<p>Well now that we can transparently cache our dependencies, let&#8217;s build something interesting. We are going to build a classifier that predicts whether text may have come from HN or Reddit, and also specifically which sub.</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>python social_media.py
</pre></div>
</div>
<p>This spins up our classifier:</p>
<div class="highlight-python"><div class="highlight"><pre>getting hn showstories - this may take a while!
got 63 titles in 1.221211 seconds
getting hn askstories - this may take a while!
got 80 titles in 5.147536 seconds
getting hn jobstories - this may take a while!
got 22 titles in 0.046783 seconds
getting reddit data for republican
getting reddit data for democrat
getting reddit data for linux
getting reddit data for music
getting reddit data for movies
getting reddit data for literature
getting reddit data for books
******************************
TEST CLASSIFIER
******************************
&#39;powershell and openssl compatability testing&#39; =&gt; (&#39;reddit&#39;, &#39;linux&#39;)
&#39;compiling source code on ubuntu&#39; =&gt; (&#39;reddit&#39;, &#39;linux&#39;)
&#39;wifi drivers keep crashing&#39; =&gt; (&#39;reddit&#39;, &#39;linux&#39;)
&#39;cron jobs&#39; =&gt; (&#39;reddit&#39;, &#39;republican&#39;)
&#39;training day was a great movie with a legendary director&#39; =&gt; (&#39;reddit&#39;, &#39;movies&#39;)
&#39;michael bay should remake lord of the rings, set in the future&#39; =&gt; (&#39;reddit&#39;, &#39;books&#39;)
&quot;hilary clinton may win voters&#39; hearts&quot; =&gt; (&#39;reddit&#39;, &#39;republican&#39;)
&#39;donald trump may donimate the presidency&#39; =&gt; (&#39;reddit&#39;, &#39;republican&#39;)
&#39;reading dead wood gives me far more pleasure than using kindles&#39; =&gt; (&#39;reddit&#39;, &#39;books&#39;)
&#39;hiring a back end engineer&#39; =&gt; (&#39;hn&#39;, &#39;jobstories&#39;)
&#39;guitar is louder than the piano although electronic is best&#39; =&gt; (&#39;reddit&#39;, &#39;music&#39;)
&#39;drum solo and singer from the rolling stones&#39; =&gt; (&#39;reddit&#39;, &#39;music&#39;)
&#39;hiring a back end engineer&#39; =&gt; (&#39;hn&#39;, &#39;jobstories&#39;)
&#39;javascript loader&#39; =&gt; (&#39;hn&#39;, &#39;showstories&#39;)
&quot;dostoevsky&#39;s existentialism&quot; =&gt; (&#39;reddit&#39;, &#39;literature&#39;)
Enter title: 
</pre></div>
</div>
<p>Everything under <em>TEST CLASSIFIER</em> is the result of running these strings through the classifier. Let&#8217;s break this down, and see how it works. Feel free to type in text, and see how the classifier holds up. See whether you can formuate sentences that would fall within the specified subs.</p>
</div>
<div class="section" id="social-media-py">
<h2>./social_media.py<a class="headerlink" href="#social-media-py" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">lib</span> <span class="kn">import</span> <span class="n">dataMiner</span>

<span class="n">titles</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">dataMiner</span><span class="o">.</span><span class="n">doMining</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>

<span class="n">count_vect</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">X_train_counts</span> <span class="o">=</span> <span class="n">count_vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">titles</span><span class="p">)</span>

<span class="n">tfidf_transformer</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">()</span>
<span class="n">X_train_tfidf</span> <span class="o">=</span> <span class="n">tfidf_transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_counts</span><span class="p">)</span>
</pre></div>
</div>
<p>Scikitlearn has a high level component <code class="docutils literal"><span class="pre">CountVectorizer</span></code> that takes care of text preprocessing, tokenizing and filtering of stopwords for us. It transforms our text into feature vectors, in the form of a dictionary:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">tests</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">&quot;powershell and openssl compatability testing&quot;</span><span class="p">,</span>
    <span class="s">&quot;compiling source code on ubuntu&quot;</span><span class="p">,</span>
    <span class="s">&quot;wifi drivers keep crashing&quot;</span><span class="p">,</span>
    <span class="s">&quot;cron jobs&quot;</span><span class="p">,</span>
    <span class="s">&quot;training day was a great movie with a legendary director&quot;</span><span class="p">,</span>
</pre></div>
</div>
<p>You can check the score for various tokens, i.e.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">count_vect</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">u&quot;solarcity&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output: 13350</p>
<p>We need to build a tf–idf (term frequency times inverse document frequency) transformer. This is to prevent larger documents to score higher, by having occurances score higher due to document size instead of token term relevance, which is why the fix is to divide the term frequencies by the document size.</p>
<div class="highlight-python"><div class="highlight"><pre>    <span class="s">&quot;training day was a great movie with a legendary director&quot;</span><span class="p">,</span>
    <span class="s">&quot;michael bay should remake lord of the rings, set in the future&quot;</span><span class="p">,</span>
    <span class="s">&quot;hilary clinton may win voters&#39; hearts&quot;</span><span class="p">,</span>
    <span class="s">&quot;donald trump may donimate the presidency&quot;</span><span class="p">,</span>
    <span class="s">&quot;reading dead wood gives me far more pleasure than using kindles&quot;</span><span class="p">,</span>
    <span class="s">&quot;hiring a back end engineer&quot;</span><span class="p">,</span>
</pre></div>
</div>
<p>And finally our <code class="docutils literal"><span class="pre">predict</span></code> function, which takes an array of sentences.</p>
<div class="highlight-python"><div class="highlight"><pre>    <span class="s">&quot;hiring a back end engineer&quot;</span><span class="p">,</span>
    <span class="s">&quot;javascript loader&quot;</span><span class="p">,</span>
    <span class="s">&quot;dostoevsky&#39;s existentialism&quot;</span>
<span class="p">]</span>

<span class="n">predict</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</pre></div>
</div>
<p>We can now run our example sentences, and go into our main prediction loop.</p>
</div>
<div class="section" id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="Permalink to this headline">¶</a></h2>
<p>Indulge me, dear reader, with this thought expriment. Imagine a whole department of developers standing up at once, glancing at each other, and walking away for an &#8220;extended lunch-break&#8221; while the department next door desperately scrambles to get the culprit service back up.</p>
<p>You suddenly realise it&#8217;s not only you who can no longer work: no one can. Little by little, chaos sets in: people start wondering around, talking about their weekends, playing table football, throwing things around. This is the corporate equivalent to a big money bonfire.</p>
<p>Now here comes the thought expement: what could you have done, as an engineer, to prevent this all to common situation?</p>
</div>
<div class="section" id="you-are-affected-but-the-problem-wasn-t-you">
<h2>You are affected, but the problem wasn&#8217;t you<a class="headerlink" href="#you-are-affected-but-the-problem-wasn-t-you" title="Permalink to this headline">¶</a></h2>
<p>One technique to avoid these &#8220;real world&#8221; unpredictabilities is mocking. And I&#8217;m not using quotes around &#8220;real world&#8221; to pretend that I know better than people who don&#8217;t. I&#8217;m using them as sometimes one has to stand in awe at the gradual decay of the internet, and how we put up with it.</p>
<p>How many of your bookmarks no longer work? URLs fade into the darkness, and along with them your data. The issue with mocking however is that it tests your code against expected data. What happens when the network gets slow, is wrong, or fails entirely?</p>
<p>To solve this issue I recently wrote a python binding to a wonderful Service Virtualisation application called HoverFly. HoverFly is an ultra-fast light-weight proxy written in GoLang. Using it was a true eye-opener for me, as I can now completely isolate myself from the big nasty and unpredictable world, while pretending its still there.</p>
<p>On my search for dependencies for this blog post, I thought what better than using Hacker News and Reddit. Hacker News is hosted on firebase, which has no rate limit and is actually quite fast. Getting data from Reddit however is a completely different story all together. The rate limit is very low, making it the perfect dependency one cannot depend upon.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="#">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Speeding up Machine Learning using a high-performance Go proxy.</a><ul>
<li><a class="reference internal" href="#data-mining-hackernews-and-reddit">Data mining HackerNews and Reddit</a><ul>
<li><a class="reference internal" href="#lib-hnminer-py">./lib/hnMiner.py</a></li>
</ul>
</li>
<li><a class="reference internal" href="#putting-our-miners-together">Putting our miners together</a></li>
<li><a class="reference internal" href="#building-an-hn-or-reddit-classifier">Building an HN or Reddit classifier</a></li>
<li><a class="reference internal" href="#social-media-py">./social_media.py</a></li>
<li><a class="reference internal" href="#testing">Testing</a></li>
<li><a class="reference internal" href="#you-are-affected-but-the-problem-wasn-t-you">You are affected, but the problem wasn&#8217;t you</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/index.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Shyal Beardsley.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.3.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/index.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>