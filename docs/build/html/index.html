<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Buliding a Python social media classifier using a GoLang Service Virtualiser. &mdash; social_media 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="social_media 1.0 documentation" href="#" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="buliding-a-python-social-media-classifier-using-a-golang-service-virtualiser">
<h1>Buliding a Python  social media classifier using a GoLang Service Virtualiser.<a class="headerlink" href="#buliding-a-python-social-media-classifier-using-a-golang-service-virtualiser" title="Permalink to this headline">¶</a></h1>
<p>(consider: bringing data mining to the 21st century. Can hoverfly be a tool that aids data mining?)</p>
<div class="toctree-wrapper compound">
<ul class="simple">
</ul>
</div>
<p>Indulge me, dear reader, with this thought expriment. Imagine a whole department of developers standing up at once, glancing at each other, and walking away for an &#8220;extended lunch-break&#8221; while the department next door desperately scrambles to get the culprit service back up.</p>
<div class="figure">
<img alt="sometimes the world can be an unpredictable place" src="_images/1ftcd5.jpg" />
</div>
<p>You suddenly realise it&#8217;s not only you who can no longer work: no one can. Little by little, chaos sets in: people start wondering around, talking about their weekends, playing table football, throwing things around. This is the corporate equivalent to a big money bonfire.</p>
<p>Now here comes the thought expement: what could you have done, as an engineer, to prevent this all to common situation?</p>
<div class="section" id="you-are-affected-but-the-problem-wasn-t-you">
<h2>You are affected, but the problem wasn&#8217;t you<a class="headerlink" href="#you-are-affected-but-the-problem-wasn-t-you" title="Permalink to this headline">¶</a></h2>
<p>One technique to avoid these &#8220;real world&#8221; unpredictabilities is mocking. And I&#8217;m not using quotes around &#8220;real world&#8221; to pretend that I know better than people who don&#8217;t. I&#8217;m using them as sometimes one has to stand in awe at the gradual decay of the internet, and how we put up with it.</p>
<p>How many of your bookmarks no longer work? URLs fade into the darkness, and along with them your data. The issue with mocking however is that it tests your code against expected data. What happens when the network gets slow, is wrong, or fails entirely?</p>
<p>To solve this issue I recently wrote a python binding to a wonderful Service Virtualisation application called HoverFly. HoverFly is an ultra-fast light-weight proxy written in GoLang. Using it was a true eye-opener for me, as I can now completely isolate myself from the big nasty and unpredictable world, while pretending its still there.</p>
<p>On my search for dependencies for this blog post, I thought what better than using Hacker News and Reddit. Hacker News is hosted on firebase, which has no rate limit and is actually quite fast. Getting data from Reddit however is a completely different story all together. The rate limit is very low, making it the perfect dependency one cannot depend upon.</p>
</div>
<div class="section" id="virtualising-dependencies">
<h2>Virtualising Dependencies<a class="headerlink" href="#virtualising-dependencies" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s get going:</p>
<div class="highlight-bash"><div class="highlight"><pre>pip install hoverpy
python
</pre></div>
</div>
<p>Let&#8217;s get the top 100 posts on HackerNews</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">hoverpy</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">argparse</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
    <span class="s">&quot;--capture&quot;</span><span class="p">,</span>
    <span class="n">help</span><span class="o">=</span><span class="s">&quot;capture the data from hackernews&quot;</span><span class="p">,</span>
    <span class="n">action</span><span class="o">=</span><span class="s">&quot;store_true&quot;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">with</span> <span class="n">hoverpy</span><span class="o">.</span><span class="n">HoverPy</span><span class="p">(</span><span class="n">capture</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">capture</span><span class="p">):</span>
    <span class="n">prot</span> <span class="o">=</span> <span class="s">&quot;https&quot;</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">capture</span> <span class="k">else</span> <span class="s">&quot;http&quot;</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="s">&quot;</span><span class="si">%s</span><span class="s">://hacker-news.firebaseio.com/v0/topstories.json&quot;</span> <span class="o">%</span> <span class="n">prot</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">json</span><span class="p">()[:</span><span class="mi">100</span><span class="p">]:</span>
        <span class="n">it</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s">&quot;</span><span class="si">%s</span><span class="s">://hacker-news.firebaseio.com/v0/item/</span><span class="si">%i</span><span class="s">.json&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">prot</span><span class="p">,</span> <span class="n">item</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s">&quot;title&quot;</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;time taken: </span><span class="si">%f</span><span class="s"> seconds&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
</div>
<p>Let&#8217;s run this, and get the top 100 titles on HN:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>./hn_titles.py --capture

<span class="o">[</span>...<span class="o">]</span>
London house prices are having a relatively bad December
Interview with Max Levchin

<span class="nb">time </span>taken: 15.888608 seconds.
</pre></div>
</div>
<p>Time taken: <strong>15.888608 seconds</strong>. I don&#8217;t know about you, but working with dependencies that take around 15 seconds on each run is simply not workable. So Let&#8217;s now see what happens when we run this code in simulate mode.</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>./hn_titles.py --capture

<span class="o">[</span>...<span class="o">]</span>
London house prices are having a relatively bad December
Interview with Max Levchin

<span class="nb">time </span>taken: 0.196227 seconds.
</pre></div>
</div>
<p>Time taken: <strong>0.196227 seconds</strong>. That&#8217;s a lot better!</p>
</div>
<div class="section" id="data-mining-and-caching">
<h2>Data mining and caching<a class="headerlink" href="#data-mining-and-caching" title="Permalink to this headline">¶</a></h2>
<p>In this example we are going to use Hoverfly to harvest our data, however please remember it also caches POSTS, PUTS etc. as well as all for mutating responses via middleware. In fact I could have used it with libraries like Praw or Haxor, but I decided to hit the endpoints directly for efficiency.</p>
</div>
<div class="section" id="building-an-hn-or-reddit-classifier">
<h2>Building an HN or Reddit classifier<a class="headerlink" href="#building-an-hn-or-reddit-classifier" title="Permalink to this headline">¶</a></h2>
<div class="figure">
<img alt="hat" src="_images/hat.jpg" />
</div>
<p>Well now that we can transparently cache our dependencies, let&#8217;s build something interesting. We are going to build a classifier that predicts whether text may have come from HN or Reddit, and also specifically which sub.</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>python social_media.py --comments --text
</pre></div>
</div>
<p>This spins up our classifier:</p>
<div class="highlight-python"><div class="highlight"><pre>getting hn showstories - this may take a while!
got 63 titles in 1.221211 seconds
getting hn askstories - this may take a while!
got 80 titles in 5.147536 seconds
getting hn jobstories - this may take a while!
got 22 titles in 0.046783 seconds
getting reddit data for republican
getting reddit data for democrat
getting reddit data for linux
getting reddit data for music
getting reddit data for movies
getting reddit data for literature
getting reddit data for books
******************************
TEST CLASSIFIER
******************************
&#39;powershell and openssl compatability testing&#39; =&gt; (&#39;reddit&#39;, &#39;linux&#39;)
&#39;compiling source code on ubuntu&#39; =&gt; (&#39;reddit&#39;, &#39;linux&#39;)
&#39;wifi drivers keep crashing&#39; =&gt; (&#39;reddit&#39;, &#39;linux&#39;)
&#39;cron jobs&#39; =&gt; (&#39;reddit&#39;, &#39;republican&#39;)
&#39;training day was a great movie with a legendary director&#39; =&gt; (&#39;reddit&#39;, &#39;movies&#39;)
&#39;michael bay should remake lord of the rings, set in the future&#39; =&gt; (&#39;reddit&#39;, &#39;books&#39;)
&quot;hilary clinton may win voters&#39; hearts&quot; =&gt; (&#39;reddit&#39;, &#39;republican&#39;)
&#39;donald trump may donimate the presidency&#39; =&gt; (&#39;reddit&#39;, &#39;republican&#39;)
&#39;reading dead wood gives me far more pleasure than using kindles&#39; =&gt; (&#39;reddit&#39;, &#39;books&#39;)
&#39;hiring a back end engineer&#39; =&gt; (&#39;hn&#39;, &#39;jobstories&#39;)
&#39;guitar is louder than the piano although electronic is best&#39; =&gt; (&#39;reddit&#39;, &#39;music&#39;)
&#39;drum solo and singer from the rolling stones&#39; =&gt; (&#39;reddit&#39;, &#39;music&#39;)
&#39;hiring a back end engineer&#39; =&gt; (&#39;hn&#39;, &#39;jobstories&#39;)
&#39;javascript loader&#39; =&gt; (&#39;hn&#39;, &#39;showstories&#39;)
&quot;dostoevsky&#39;s existentialism&quot; =&gt; (&#39;reddit&#39;, &#39;literature&#39;)
Enter title: 
</pre></div>
</div>
<p>Everything under <em>TEST CLASSIFIER</em> is the result of running these strings through the classifier. Let&#8217;s break this down, and see how it works. Feel free to type in text, and see how the classifier holds up.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">lib.parseArgs</span> <span class="kn">import</span> <span class="n">args</span>

<span class="n">subs</span> <span class="o">=</span> <span class="p">[(</span><span class="s">&#39;hn&#39;</span><span class="p">,</span> <span class="s">&#39;showstories&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;hn&#39;</span><span class="p">,</span> <span class="s">&#39;askstories&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;hn&#39;</span><span class="p">,</span> <span class="s">&#39;jobstories&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;republican&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;democrat&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;linux&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;music&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;movies&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;literature&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;reddit&#39;</span><span class="p">,</span> <span class="s">&#39;books&#39;</span><span class="p">)]</span>
</pre></div>
</div>
<p>Above we simply build an array of subs.</p>
<p>Please note, if you are copy and pasting these examples, you&#8217;ll need to set some args to true here:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">args</span><span class="o">.</span><span class="n">comments</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">args</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
<p>Next, we built out getters, and then actually went to fetch the post titles, text, and comments from HN and Reddit.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">titles</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">target</span> <span class="o">=</span> <span class="p">[]</span>

<span class="kn">from</span> <span class="nn">lib.hn_helpers</span> <span class="kn">import</span> <span class="n">getHNData</span>
<span class="kn">from</span> <span class="nn">lib.reddit_helpers</span> <span class="kn">import</span> <span class="n">getRedditData</span>

<span class="n">getter</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;hn&#39;</span><span class="p">:</span> <span class="n">getHNData</span><span class="p">,</span> <span class="s">&#39;reddit&#39;</span><span class="p">:</span> <span class="n">getRedditData</span><span class="p">}</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subs</span><span class="p">)):</span>
    <span class="n">subTitles</span> <span class="o">=</span> <span class="n">getter</span><span class="p">[</span><span class="n">subs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]](</span>
        <span class="n">sub</span><span class="o">=</span><span class="n">subs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
    <span class="n">titles</span> <span class="o">+=</span> <span class="n">subTitles</span>
    <span class="n">target</span> <span class="o">+=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">subTitles</span><span class="p">)</span>
</pre></div>
</div>
<p>Scikitlearn has a high level component that takes care of text preprocessing, tokenizing and filtering of stopwords for us. It transforms our text into feature vectors, in the form of a dictionary:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>

<span class="n">count_vect</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">X_train_counts</span> <span class="o">=</span> <span class="n">count_vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">titles</span><span class="p">)</span>
</pre></div>
</div>
<p>You can check the score for various tokens, i.e.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">count_vect</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">u&quot;solarcity&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output: 13350</p>
<p>We need to build a tf–idf (term frequency times inverse document frequency) transformer. This is to prevent larger documents to score higher, by having occurances score higher due to document size instead of token term relevance, which is why the fix is to divide the term frequencies by the document size.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">X_train_counts</span> <span class="o">=</span> <span class="n">count_vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">titles</span><span class="p">)</span>

<span class="n">tfidf_transformer</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">()</span>
<span class="n">X_train_tfidf</span> <span class="o">=</span> <span class="n">tfidf_transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_counts</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_tfidf</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
<p>And finally our <code class="docutils literal"><span class="pre">predict</span></code> function, which takes an array of sentences.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
    <span class="n">X_new_counts</span> <span class="o">=</span> <span class="n">count_vect</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
    <span class="n">X_new_tfidf</span> <span class="o">=</span> <span class="n">tfidf_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_new_counts</span><span class="p">)</span>

    <span class="n">predicted</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new_tfidf</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">category</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;</span><span class="si">%r</span><span class="s"> =&gt; </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">subs</span><span class="p">[</span><span class="n">category</span><span class="p">]))</span>
</pre></div>
</div>
<p>We can now run our example sentences, and go into our main prediction loop.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">tests</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">&quot;powershell and openssl compatability testing&quot;</span><span class="p">,</span>
    <span class="s">&quot;compiling source code on ubuntu&quot;</span><span class="p">,</span>
    <span class="s">&quot;wifi drivers keep crashing&quot;</span><span class="p">,</span>
    <span class="s">&quot;cron jobs&quot;</span><span class="p">,</span>
    <span class="s">&quot;training day was a great movie with a legendary director&quot;</span><span class="p">,</span>
    <span class="s">&quot;michael bay should remake lord of the rings, set in the future&quot;</span><span class="p">,</span>
    <span class="s">&quot;hilary clinton may win voters&#39; hearts&quot;</span><span class="p">,</span>
    <span class="s">&quot;donald trump may donimate the presidency&quot;</span><span class="p">,</span>
    <span class="s">&quot;reading dead wood gives me far more pleasure than using kindles&quot;</span><span class="p">,</span>
    <span class="s">&quot;hiring a back end engineer&quot;</span><span class="p">,</span>
    <span class="s">&quot;guitar is louder than the piano although electronic is best&quot;</span><span class="p">,</span>
    <span class="s">&quot;drum solo and singer from the rolling stones&quot;</span><span class="p">,</span>
    <span class="s">&quot;hiring a back end engineer&quot;</span><span class="p">,</span>
    <span class="s">&quot;javascript loader&quot;</span><span class="p">,</span>
    <span class="s">&quot;dostoevsky&#39;s existentialism&quot;</span>
<span class="p">]</span>

<span class="n">predict</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">predict</span><span class="p">([</span><span class="nb">raw_input</span><span class="p">(</span><span class="s">&quot;Enter title: &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()])</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="#">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Buliding a Python  social media classifier using a GoLang Service Virtualiser.</a><ul>
<li><a class="reference internal" href="#you-are-affected-but-the-problem-wasn-t-you">You are affected, but the problem wasn&#8217;t you</a></li>
<li><a class="reference internal" href="#virtualising-dependencies">Virtualising Dependencies</a></li>
<li><a class="reference internal" href="#data-mining-and-caching">Data mining and caching</a></li>
<li><a class="reference internal" href="#building-an-hn-or-reddit-classifier">Building an HN or Reddit classifier</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/index.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Shyal Beardsley.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.3.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/index.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>